          
本系统基于 Linux 下的 Socket 网络编程，以 TCP 为核心实现可靠的点到点字节流通信，并在服务器端采用 epoll 非阻塞多路复用模型实现高并发连接管理。服务器通过 `socket→setsockopt→bind→listen` 初始化监听套接字（server/server.c:260–305），再将监听 FD 注册到 epoll（server/server.c:318–327），进入事件循环等待连接与数据（server/server.c:331–343）。每当有新连接到来，使用非阻塞 `accept` 接收并设置客户端 FD 为非阻塞（server/server.c:348–377），随后将其加入 epoll 关注集合（server/server.c:381–389），同时在内存里创建 `ClientInfo` 并维护在线状态（include/protocol.h:33–39；server/server.c:400–407）。客户端通过 `socket→connect` 主动建立 TCP 连接（client/client.c:58–77），其主线程接收用户输入并根据命令包装协议发送（client/client.c:122–168），同时创建接收线程独立阻塞在 `recv` 上，将服务端推送的消息解包后实时打印（client/client.c:82–86, 178–219），当 `recv==0` 或出现错误则设置连接关闭标志并通知主线程退出（client/client.c:222–239, 97–107）。

在多路复用方面，服务器端全流程采用 epoll，先通过 `epoll_create1(0)` 建立实例（server/server.c:309–315），用 `epoll_ctl` 将监听 FD 和每个客户端 FD 注册为可读事件（server/server.c:318–327, 382–389），使用 `epoll_wait` 在主线程中等待就绪事件集合（server/server.c:331–339）。这种事件驱动架构以单线程管理所有连接，避免了传统每连接一线程的上下文切换开销，同时配合非阻塞 FD（server/server.c:28–40, 375–379）防止阻塞链式传播，实现较低资源消耗与较高伸缩性。虽然题目要求支持 select/poll/epoll 至少一种，本实现选择 epoll，若需要兼容 select/poll，可将事件循环抽象成通用接口并替换为 `select(fd_set)` 或 `poll(struct pollfd[])` 的待就绪集合枚举，保持消息分发逻辑不变。

关于自定义通信协议，系统以 `ChatPacket` 为统一的应用层载体，包含消息类型 `type`、有效载荷长度 `length`、发送者 `sender` 和数据体 `data`（include/protocol.h:25–31），消息类型定义了客户端/服务器的语义边界，包括注册、公聊、私聊、用户列表、断开以及系统消息等（include/protocol.h:13–23）。客户端与服务器均通过 `pack_message` 和 `unpack_message` 进行序列化与反序列化，保证数据对齐和边界安全（server/protocol.c:4–26, 29–39）。例如客户端发送命令统一走 `send_command_to_server` 包装（client/client.c:35–40），服务器端按 `packet.type` 进入路由分发（server/server.c:66–161）。公聊在服务器端打印后调用 `broadcast_message` 构造统一包并遍历在线列表逐个 `send`（server/server.c:94–101, 163–173），私聊以 `data="target:message"` 为约定，将目标名与消息以冒号分隔，服务器解析后查找目标用户并向其定向发送，同时给发送者返回确认或错误提示（server/server.c:103–135, 216–224）。用户列表由服务器按 `clients[]` 中 `logged_in` 标志拼接成逗号分隔字符串返回（server/server.c:186–214），客户端接收后以专用标签展示（client/client.c:210–213）。这种轻量协议在保证实现简单的同时，保留了 `sender` 字段用于标识来源，增强可读性与审计能力。

在线程/进程模型方面，服务器采用“单进程单线程 + epoll”事件驱动模式管理所有连接，核心优点在于内核就绪事件集中通知、用户态一次遍历即可处理多连接数据，因而不需要在服务器端显式创建线程，这也避免了共享数据结构的同步问题。客户端采用“双线程模型”，主线程专职读取用户输入并发送消息，接收线程专职读取服务器下行消息并即时呈现（client/client.c:82–86, 178–219）。两线程之间通过全局 `connection_closed` 与互斥锁进行状态同步，防止阻塞输入导致退出不及时（client/client.c:13–16, 97–107, 231–233）。如果需要扩展为服务器多线程，可在 epoll 主循环中将“消息解析与业务处理”投递到线程池执行，主线程仅负责 I/O 事件收集与 FD 管理，数据结构如 `clients[]` 则需引入细粒度锁或基于消息队列进行串行化更新，以避免竞态。该模式在高 CPU 场景（例如复杂业务逻辑）能提升利用率，但也带来锁争用与调度复杂度的权衡。

错误处理、超时与异常连接处理贯穿网络与应用层。服务器端对 `recv<=0` 的情况统一视为断开或错误，若为正常登录用户则构造系统消息广播并执行资源清理，包含 `close` 套接字与从 `clients[]` 移除（server/server.c:48–63, 236–251）。在 epoll 事件中还监控 `EPOLLERR|EPOLLHUP` 用以捕捉错误或挂起并进行清理（server/server.c:418–431）。客户端接收线程在 `recv==0` 或错误时打印友好提示，设置断开标志以唤醒主线程退出（client/client.c:222–239），主线程循环首部每次检查该标志避免卡在阻塞输入（client/client.c:97–107）。超时机制在当前实现中以“无超时阻塞”策略处理（`epoll_wait` 使用 `-1` 无超时，client 读输入阻塞），如果需要请求/心跳超时，可在服务器端改用有限 `epoll_wait(timeout)` 并配合“最近活跃时间”进行心跳检查，或在客户端/服务器套接字上设置 `SO_RCVTIMEO/SO_SNDTIMEO` 针对阻塞调用的时间限制；对于应用级命令超时，可在客户端引入基于 `select` 的多源轮询同时监控 `STDIN` 与 `sockfd`，从而避免 `fgets` 永久阻塞并能及时响应服务器端断开，这在断开检测说明文档中已有设计探讨。

文件写入（聊天日志）功能在现有版本中未默认开启，但对系统工程而言，推荐在服务器侧统一记录关键事件，包括公聊、私聊、用户上下线与异常。实现思路是在服务器 `main` 初始化时打开一次 `chat.log` 文件句柄，在公聊处理、私聊处理与上下线广播处写入一行结构化日志，再在退出时关闭。示例位置与最小改动如下：公聊在 `case MSG_PUBLIC_CHAT` 路径写入（server/server.c:94–101），私聊在定向转发与确认处写入（server/server.c:121–127, 115–120），上线在注册成功后与加入广播处写入（server/server.c:76–90），离线在断开或显式 `MSG_DISCONNECT` 处写入（server/server.c:55–60, 149–151）。对应代码片段可以在广播函数中集中记录，避免分散：

```c
// 伪示例：在 server/server.c 的 broadcast_message 中追加持久化
// FILE *logf; // 在 main 初始化：logf = fopen("chat.log","a");
ChatPacket packet;
pack_message(&packet, msg_type, sender, message);
for (int i = 0; i < client_count; i++) {
    if (clients[i] && clients[i]->logged_in && clients[i]->sockfd != exclude_fd) {
        send(clients[i]->sockfd, &packet, sizeof(ChatPacket), 0);
    }
}
// fprintf(logf, "%ld|%d|%s|%s\n", time(NULL), msg_type, sender, message); fflush(logf);
```

如果更希望在业务分支处精准记录上下文，可在 `handle_client_message` 的各分支写入，例如：

```c
// 公聊记录：server/server.c:94–101
printf("[公开] %s: %s\n", client->name, packet.data);
// fprintf(logf, "%ld|PUBLIC|%s|%s\n", time(NULL), client->name, packet.data);

// 私聊记录：server/server.c:121–127
printf("[私聊] %s -> %s: %s\n", client->name, target_name, message);
// fprintf(logf, "%ld|PRIVATE|%s->%s|%s\n", time(NULL), client->name, target_name, message);
```

总之，系统在网络层采用 TCP 套接字与 epoll 事件模型形成高效的 I/O 管理，在协议层通过轻量的 `ChatPacket` 统一消息语义，在并发层客户端以双线程分离输入与接收、服务器以单线程事件驱动避免锁与线程管理开销，在可靠性层对断开、错误与异常进行统一处理，且预留了超时与心跳的扩展点；日志模块建议在服务器端统一收集以便测试验收与线上审计。上述所有实现的关键代码位置与调用关系在当前仓库中清晰可查：服务器主流程与事件处理在 server/server.c:254–448，协议定义与编解包在 include/protocol.h 与 server/protocol.c，客户端命令解析与接收线程在 client/client.c:42–239，构建脚本在 Makefile:1–51。